{"name":"Tokenrecognizer","tagline":"A scanner or lexical analyzer using lex and C for a Functional Language FP","body":"\r\n                      ____ ____ ____ _  _ _  _ ____ ____ \r\n                      [__  |    |__| |\\ | |\\ | |___ |__/ \r\n                      ___] |___ |  | | \\| | \\| |___ |  \\ \r\n                                                         \r\nHow to run:\r\n\r\n1. Unzip the file\r\n\r\n2. Goto folder in terminal\r\n\r\n3. Compile command$: make\r\n\t\t(compiles the cfp.exe with FP.lex)\r\n\r\n4. Run command$: ./cfp.exe < sample1.fp \r\n\t\t(This will print the output on the console, you can try other input files as well, sample2.fp and sample3.fp)\r\n\r\n5. Run command$: ./cfp.exe < sample1.fp > sample1.output\r\n\t\t(This will print the output to the sample1.output file)\r\n\r\n6. Clean command$: make clean\r\n\t\t\r\n7. Note about the sample*.fp files\r\n\r\n   - sample1.fp is the sample file that is given on the professor's homepage\r\n\r\n   - sample2.fp and sample3.fp demonstrates proper tokenizations of \r\n\t -ve integer,\r\n\t -ve integer with spaces in between sign and digits,\r\n\t -boolean variables usage\r\n\t -integer bound of 10,000,000 (10,000,001 or more not allowed)\r\n\r\n\r\n7. All the outputs are provided in the sample*.output files in the submission.\r\n\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}